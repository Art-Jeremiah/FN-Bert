{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80c08cf0-820b-484a-b3de-3b1d23480f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from src.utils.trainer import train\n",
    "from src.utils.options import Args\n",
    "from src.utils.model_utils import build_model\n",
    "from src.utils.dataset_utils import NERDataset\n",
    "from src.utils.evaluator import crf_evaluation, span_evaluation, mrc_evaluation\n",
    "from src.utils.functions_utils import set_seed, get_model_path_list, load_model_and_parallel, get_time_dif\n",
    "from src.preprocess.processor import NERProcessor, convert_examples_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5a9c6-f500-4eeb-8791-d310bc706332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MID_DATA_DIR, f'{TASK_TYPE}_ent2id.json'), encoding='utf-8') as f:\n",
    "    ent2id = json.load(f)\n",
    "id2ent = {ent2id[key]: key for key in ent2id.keys()}\n",
    "tokenizer = BertTokenizer(os.path.join(BERT_DIR, 'vocab.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4f9ada8-74e5-4298-8efe-92a66063a471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CRFFeature' object has no attribute 'ent_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mfinal_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./bert/torch_uer_large\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/raw_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/mid_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mfinal_evaluation\u001b[0;34m(task_type, max_seq_len, bert_dir, raw_data_dir, mid_data_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m dev_examples \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mget_examples(dev_raw_examples, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_to_use\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m dev_features, dev_callback_info \u001b[38;5;241m=\u001b[39m convert_examples_to_features(task_type, dev_examples,\n\u001b[1;32m      8\u001b[0m                                                                max_seq_len, bert_dir, ent2id)\n\u001b[0;32m---> 11\u001b[0m dev_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNERDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_to_use\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_type_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m dev_loader \u001b[38;5;241m=\u001b[39m DataLoader(dev_dataset, batch_size\u001b[38;5;241m=\u001b[39meval_batch_size,\n\u001b[1;32m     14\u001b[0m                         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m dev_info \u001b[38;5;241m=\u001b[39m (dev_loader, dev_callback_info)\n",
      "File \u001b[0;32m~/DeepNER/src/utils/dataset_utils.py:27\u001b[0m, in \u001b[0;36mNERDataset.__init__\u001b[0;34m(self, task_type, features, mode, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_ids \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39mend_ids)\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_type_embed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_type \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39ment_type) \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m features]\n",
      "File \u001b[0;32m~/DeepNER/src/utils/dataset_utils.py:27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_ids \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39mend_ids)\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_type_embed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ment_type \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ment_type\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m features]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CRFFeature' object has no attribute 'ent_type'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    final_evaluation('crf',512,\"./bert/torch_uer_large\",\"./data/raw_data\",\"./data/mid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90997ee-606e-4b0e-b1b5-f7b2d164ac81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
